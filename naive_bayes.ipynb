{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07647f4d",
   "metadata": {},
   "source": [
    "# Naives Bayes (get a probability of a comment being 'sarcasm' or 'bullying' given 'a word'  is in this comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8772bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords \n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import recall_score, accuracy_score, precision_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405929ba",
   "metadata": {},
   "source": [
    "## Fetching the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ffd440c",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.read_csv('merged_all_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e3d07d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_cleaned</th>\n",
       "      <th>Words Per Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>wow it is totally unreasonable to assume that ...</td>\n",
       "      <td>wow it is totally unreasonable to assume that ...</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>443</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>A WHITE FUCKIN MALE is out to destroy 2 strong...</td>\n",
       "      <td>a WHITE FUCKIN MALE is out to destroy  strong,...</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>807</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>He probably just didn't want to read them beca...</td>\n",
       "      <td>he probably just didn't want to read them beca...</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1745</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>It's like he's saying we're entering a post ge...</td>\n",
       "      <td>it's like he's saying we're entering a post ge...</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>But it was clearly only dismissed because of d...</td>\n",
       "      <td>but it was clearly only dismissed because of d...</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42497</th>\n",
       "      <td>47687</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>Black ppl aren't expected to do anything, depe...</td>\n",
       "      <td>black ppl aren't expected to do anything, depe...</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42498</th>\n",
       "      <td>47688</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>Turner did not withhold his disappointment. Tu...</td>\n",
       "      <td>turner did not withhold his disappointment. Tu...</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42499</th>\n",
       "      <td>47689</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>I swear to God. This dumb nigger bitch. I have...</td>\n",
       "      <td>i swear to God. This dumb nigger bitch. I have...</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42500</th>\n",
       "      <td>47690</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>Yea fuck you RT @therealexel: IF YOURE A NIGGE...</td>\n",
       "      <td>yea fuck you RT  IF YOURE A NIGGER FUCKING UNF...</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42501</th>\n",
       "      <td>47691</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>Bro. U gotta chill RT @CHILLShrammy: Dog FUCK ...</td>\n",
       "      <td>bro. U gotta chill RT  Dog FUCK KP that dumb n...</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42502 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0      label  \\\n",
       "0              44    sarcasm   \n",
       "1             443    sarcasm   \n",
       "2             807    sarcasm   \n",
       "3            1745    sarcasm   \n",
       "4            2022    sarcasm   \n",
       "...           ...        ...   \n",
       "42497       47687  ethnicity   \n",
       "42498       47688  ethnicity   \n",
       "42499       47689  ethnicity   \n",
       "42500       47690  ethnicity   \n",
       "42501       47691  ethnicity   \n",
       "\n",
       "                                                 comment  \\\n",
       "0      wow it is totally unreasonable to assume that ...   \n",
       "1      A WHITE FUCKIN MALE is out to destroy 2 strong...   \n",
       "2      He probably just didn't want to read them beca...   \n",
       "3      It's like he's saying we're entering a post ge...   \n",
       "4      But it was clearly only dismissed because of d...   \n",
       "...                                                  ...   \n",
       "42497  Black ppl aren't expected to do anything, depe...   \n",
       "42498  Turner did not withhold his disappointment. Tu...   \n",
       "42499  I swear to God. This dumb nigger bitch. I have...   \n",
       "42500  Yea fuck you RT @therealexel: IF YOURE A NIGGE...   \n",
       "42501  Bro. U gotta chill RT @CHILLShrammy: Dog FUCK ...   \n",
       "\n",
       "                                         comment_cleaned  Words Per Tweet  \n",
       "0      wow it is totally unreasonable to assume that ...             25.0  \n",
       "1      a WHITE FUCKIN MALE is out to destroy  strong,...             18.0  \n",
       "2      he probably just didn't want to read them beca...             23.0  \n",
       "3      it's like he's saying we're entering a post ge...             21.0  \n",
       "4      but it was clearly only dismissed because of d...             19.0  \n",
       "...                                                  ...              ...  \n",
       "42497  black ppl aren't expected to do anything, depe...             42.0  \n",
       "42498  turner did not withhold his disappointment. Tu...             45.0  \n",
       "42499  i swear to God. This dumb nigger bitch. I have...             20.0  \n",
       "42500  yea fuck you RT  IF YOURE A NIGGER FUCKING UNF...             15.0  \n",
       "42501  bro. U gotta chill RT  Dog FUCK KP that dumb n...             14.0  \n",
       "\n",
       "[42502 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f9b7f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label               object\n",
       "comment_cleaned     object\n",
       "Words Per Tweet    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = merged_df[['label', 'comment_cleaned', 'Words Per Tweet']]\n",
    "merged_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f59cd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['comment_cleaned'] = merged_df['comment_cleaned'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43bea20",
   "metadata": {},
   "source": [
    "## Lowercasing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f7d6826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment_cleaned</th>\n",
       "      <th>Words Per Tweet</th>\n",
       "      <th>comment_cleaned_lower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sarcasm</td>\n",
       "      <td>wow it is totally unreasonable to assume that ...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>wow it is totally unreasonable to assume that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sarcasm</td>\n",
       "      <td>a WHITE FUCKIN MALE is out to destroy  strong,...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>a white fuckin male is out to destroy  strong,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sarcasm</td>\n",
       "      <td>he probably just didn't want to read them beca...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>he probably just didn't want to read them beca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sarcasm</td>\n",
       "      <td>it's like he's saying we're entering a post ge...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>it's like he's saying we're entering a post ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sarcasm</td>\n",
       "      <td>but it was clearly only dismissed because of d...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>but it was clearly only dismissed because of d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42497</th>\n",
       "      <td>ethnicity</td>\n",
       "      <td>black ppl aren't expected to do anything, depe...</td>\n",
       "      <td>42.0</td>\n",
       "      <td>black ppl aren't expected to do anything, depe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42498</th>\n",
       "      <td>ethnicity</td>\n",
       "      <td>turner did not withhold his disappointment. Tu...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>turner did not withhold his disappointment. tu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42499</th>\n",
       "      <td>ethnicity</td>\n",
       "      <td>i swear to God. This dumb nigger bitch. I have...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>i swear to god. this dumb nigger bitch. i have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42500</th>\n",
       "      <td>ethnicity</td>\n",
       "      <td>yea fuck you RT  IF YOURE A NIGGER FUCKING UNF...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>yea fuck you rt  if youre a nigger fucking unf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42501</th>\n",
       "      <td>ethnicity</td>\n",
       "      <td>bro. U gotta chill RT  Dog FUCK KP that dumb n...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>bro. u gotta chill rt  dog fuck kp that dumb n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42502 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           label                                    comment_cleaned  \\\n",
       "0        sarcasm  wow it is totally unreasonable to assume that ...   \n",
       "1        sarcasm  a WHITE FUCKIN MALE is out to destroy  strong,...   \n",
       "2        sarcasm  he probably just didn't want to read them beca...   \n",
       "3        sarcasm  it's like he's saying we're entering a post ge...   \n",
       "4        sarcasm  but it was clearly only dismissed because of d...   \n",
       "...          ...                                                ...   \n",
       "42497  ethnicity  black ppl aren't expected to do anything, depe...   \n",
       "42498  ethnicity  turner did not withhold his disappointment. Tu...   \n",
       "42499  ethnicity  i swear to God. This dumb nigger bitch. I have...   \n",
       "42500  ethnicity  yea fuck you RT  IF YOURE A NIGGER FUCKING UNF...   \n",
       "42501  ethnicity  bro. U gotta chill RT  Dog FUCK KP that dumb n...   \n",
       "\n",
       "       Words Per Tweet                              comment_cleaned_lower  \n",
       "0                 25.0  wow it is totally unreasonable to assume that ...  \n",
       "1                 18.0  a white fuckin male is out to destroy  strong,...  \n",
       "2                 23.0  he probably just didn't want to read them beca...  \n",
       "3                 21.0  it's like he's saying we're entering a post ge...  \n",
       "4                 19.0  but it was clearly only dismissed because of d...  \n",
       "...                ...                                                ...  \n",
       "42497             42.0  black ppl aren't expected to do anything, depe...  \n",
       "42498             45.0  turner did not withhold his disappointment. tu...  \n",
       "42499             20.0  i swear to god. this dumb nigger bitch. i have...  \n",
       "42500             15.0  yea fuck you rt  if youre a nigger fucking unf...  \n",
       "42501             14.0  bro. u gotta chill rt  dog fuck kp that dumb n...  \n",
       "\n",
       "[42502 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['comment_cleaned_lower'] = merged_df['comment_cleaned'].str.lower()\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0186f9c",
   "metadata": {},
   "source": [
    "## Getting the most frequent words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83ed320",
   "metadata": {},
   "source": [
    "The most frequent words are for sure going to be stop words, so in order to find frequent occurences of meaningful words, let's create a new column which will contain the comment without the stopwords.\n",
    "\n",
    "\n",
    "This step is part of EDA - can skip this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10d8bea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment_cleaned</th>\n",
       "      <th>Words Per Tweet</th>\n",
       "      <th>comment_cleaned_lower</th>\n",
       "      <th>text_without_stop_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sarcasm</td>\n",
       "      <td>wow it is totally unreasonable to assume that ...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>wow it is totally unreasonable to assume that ...</td>\n",
       "      <td>wow totally unreasonable assume agency covered...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sarcasm</td>\n",
       "      <td>a WHITE FUCKIN MALE is out to destroy  strong,...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>a white fuckin male is out to destroy  strong,...</td>\n",
       "      <td>white fuckin male destroy strong, independent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sarcasm</td>\n",
       "      <td>he probably just didn't want to read them beca...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>he probably just didn't want to read them beca...</td>\n",
       "      <td>probably want read illegal read news media see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sarcasm</td>\n",
       "      <td>it's like he's saying we're entering a post ge...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>it's like he's saying we're entering a post ge...</td>\n",
       "      <td>like he's saying we're entering post gender so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sarcasm</td>\n",
       "      <td>but it was clearly only dismissed because of d...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>but it was clearly only dismissed because of d...</td>\n",
       "      <td>clearly dismissed death threats even though li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42497</th>\n",
       "      <td>ethnicity</td>\n",
       "      <td>black ppl aren't expected to do anything, depe...</td>\n",
       "      <td>42.0</td>\n",
       "      <td>black ppl aren't expected to do anything, depe...</td>\n",
       "      <td>black ppl expected anything, depended anything...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42498</th>\n",
       "      <td>ethnicity</td>\n",
       "      <td>turner did not withhold his disappointment. Tu...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>turner did not withhold his disappointment. tu...</td>\n",
       "      <td>turner withhold disappointment. turner called ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42499</th>\n",
       "      <td>ethnicity</td>\n",
       "      <td>i swear to God. This dumb nigger bitch. I have...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>i swear to god. this dumb nigger bitch. i have...</td>\n",
       "      <td>swear god. dumb nigger bitch. got bleach hair ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42500</th>\n",
       "      <td>ethnicity</td>\n",
       "      <td>yea fuck you RT  IF YOURE A NIGGER FUCKING UNF...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>yea fuck you rt  if youre a nigger fucking unf...</td>\n",
       "      <td>yea fuck rt youre nigger fucking unfollow me, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42501</th>\n",
       "      <td>ethnicity</td>\n",
       "      <td>bro. U gotta chill RT  Dog FUCK KP that dumb n...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>bro. u gotta chill rt  dog fuck kp that dumb n...</td>\n",
       "      <td>bro. u gotta chill rt dog fuck kp dumb nigger ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42502 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           label                                    comment_cleaned  \\\n",
       "0        sarcasm  wow it is totally unreasonable to assume that ...   \n",
       "1        sarcasm  a WHITE FUCKIN MALE is out to destroy  strong,...   \n",
       "2        sarcasm  he probably just didn't want to read them beca...   \n",
       "3        sarcasm  it's like he's saying we're entering a post ge...   \n",
       "4        sarcasm  but it was clearly only dismissed because of d...   \n",
       "...          ...                                                ...   \n",
       "42497  ethnicity  black ppl aren't expected to do anything, depe...   \n",
       "42498  ethnicity  turner did not withhold his disappointment. Tu...   \n",
       "42499  ethnicity  i swear to God. This dumb nigger bitch. I have...   \n",
       "42500  ethnicity  yea fuck you RT  IF YOURE A NIGGER FUCKING UNF...   \n",
       "42501  ethnicity  bro. U gotta chill RT  Dog FUCK KP that dumb n...   \n",
       "\n",
       "       Words Per Tweet                              comment_cleaned_lower  \\\n",
       "0                 25.0  wow it is totally unreasonable to assume that ...   \n",
       "1                 18.0  a white fuckin male is out to destroy  strong,...   \n",
       "2                 23.0  he probably just didn't want to read them beca...   \n",
       "3                 21.0  it's like he's saying we're entering a post ge...   \n",
       "4                 19.0  but it was clearly only dismissed because of d...   \n",
       "...                ...                                                ...   \n",
       "42497             42.0  black ppl aren't expected to do anything, depe...   \n",
       "42498             45.0  turner did not withhold his disappointment. tu...   \n",
       "42499             20.0  i swear to god. this dumb nigger bitch. i have...   \n",
       "42500             15.0  yea fuck you rt  if youre a nigger fucking unf...   \n",
       "42501             14.0  bro. u gotta chill rt  dog fuck kp that dumb n...   \n",
       "\n",
       "                                 text_without_stop_words  \n",
       "0      wow totally unreasonable assume agency covered...  \n",
       "1      white fuckin male destroy strong, independent ...  \n",
       "2      probably want read illegal read news media see...  \n",
       "3      like he's saying we're entering post gender so...  \n",
       "4      clearly dismissed death threats even though li...  \n",
       "...                                                  ...  \n",
       "42497  black ppl expected anything, depended anything...  \n",
       "42498  turner withhold disappointment. turner called ...  \n",
       "42499  swear god. dumb nigger bitch. got bleach hair ...  \n",
       "42500  yea fuck rt youre nigger fucking unfollow me, ...  \n",
       "42501  bro. u gotta chill rt dog fuck kp dumb nigger ...  \n",
       "\n",
       "[42502 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english')) \n",
    "merged_df['text_without_stop_words'] = merged_df['comment_cleaned_lower'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4607bbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "unmerged_df_sarcasm = merged_df[merged_df['label'] == 'sarcasm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3dd77397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the 20 most frequent words in the sarcastic comments:\n",
      "like: 1000\n",
      "people: 895\n",
      "would: 751\n",
      "get: 729\n",
      "i'm: 599\n",
      "yeah,: 547\n",
      "one: 544\n",
      "know: 542\n",
      "yeah: 523\n",
      "sure: 464\n",
      "make: 436\n",
      "well: 419\n",
      "good: 384\n",
      "can't: 381\n",
      "want: 335\n",
      "way: 332\n",
      "going: 331\n",
      "think: 329\n",
      "see: 325\n",
      "really: 323\n"
     ]
    }
   ],
   "source": [
    "# first get the strings from the dataframe column\n",
    "strings = unmerged_df_sarcasm['text_without_stop_words'].tolist()\n",
    "\n",
    "# create a list to store all words, loop through the strings and add each word to the list\n",
    "all_words = []\n",
    "for string in strings:\n",
    "    words = str(string).split()\n",
    "    all_words.extend(words)\n",
    "\n",
    "# get the 10, 20,30 most frequent words using collections.Counter\n",
    "word_counts = Counter(all_words)\n",
    "most_common_words = word_counts.most_common(20)\n",
    "\n",
    "#print them, we just do all this to have an intuition of what word(s) to pick to run our naives bayes tests\n",
    "print(\"Here are the 20 most frequent words in the sarcastic comments:\")\n",
    "for word, count in most_common_words:\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07b94367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the 20 most frequent words in the bully comments:\n",
      "school: 6816\n",
      "like: 5791\n",
      "dumb: 5112\n",
      "fuck: 5108\n",
      "high: 5026\n",
      "people: 4394\n",
      "bullied: 4153\n",
      "u: 3654\n",
      "rape: 3518\n",
      "one: 3241\n",
      "gay: 3225\n",
      "get: 2874\n",
      "nigger: 2837\n",
      "&: 2549\n",
      "rt: 2546\n",
      "ass: 2471\n",
      "girls: 2458\n",
      "black: 2449\n",
      "would: 2364\n",
      "girl: 2364\n"
     ]
    }
   ],
   "source": [
    "# first get the strings from the dataframe column\n",
    "strings = merged_df['text_without_stop_words'].tolist()\n",
    "\n",
    "# create a list to store all words, loop through the strings and add each word to the list\n",
    "all_words = []\n",
    "for string in strings:\n",
    "    words = str(string).split()\n",
    "    all_words.extend(words)\n",
    "\n",
    "# get the 10, 20,30 most frequent words using collections.Counter\n",
    "word_counts = Counter(all_words)\n",
    "most_common_words = word_counts.most_common(20)\n",
    "\n",
    "#print them, we just do all this to have an intuition of what word(s) to pick to run our naives bayes tests\n",
    "print(\"Here are the 20 most frequent words in the bully comments:\")\n",
    "for word, count in most_common_words:\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701a19b5",
   "metadata": {},
   "source": [
    "## Labelling the dataset 1 for cyberbullying, 0 for sarcasm, declaring our X and y (features and target) & performing the train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bd0300d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['label'] = np.where(merged_df['label'] == 'sarcasm', 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abef87e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment_cleaned</th>\n",
       "      <th>Words Per Tweet</th>\n",
       "      <th>comment_cleaned_lower</th>\n",
       "      <th>text_without_stop_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>wow it is totally unreasonable to assume that ...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>wow it is totally unreasonable to assume that ...</td>\n",
       "      <td>wow totally unreasonable assume agency covered...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>a WHITE FUCKIN MALE is out to destroy  strong,...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>a white fuckin male is out to destroy  strong,...</td>\n",
       "      <td>white fuckin male destroy strong, independent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>he probably just didn't want to read them beca...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>he probably just didn't want to read them beca...</td>\n",
       "      <td>probably want read illegal read news media see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>it's like he's saying we're entering a post ge...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>it's like he's saying we're entering a post ge...</td>\n",
       "      <td>like he's saying we're entering post gender so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>but it was clearly only dismissed because of d...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>but it was clearly only dismissed because of d...</td>\n",
       "      <td>clearly dismissed death threats even though li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42497</th>\n",
       "      <td>1</td>\n",
       "      <td>black ppl aren't expected to do anything, depe...</td>\n",
       "      <td>42.0</td>\n",
       "      <td>black ppl aren't expected to do anything, depe...</td>\n",
       "      <td>black ppl expected anything, depended anything...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42498</th>\n",
       "      <td>1</td>\n",
       "      <td>turner did not withhold his disappointment. Tu...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>turner did not withhold his disappointment. tu...</td>\n",
       "      <td>turner withhold disappointment. turner called ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42499</th>\n",
       "      <td>1</td>\n",
       "      <td>i swear to God. This dumb nigger bitch. I have...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>i swear to god. this dumb nigger bitch. i have...</td>\n",
       "      <td>swear god. dumb nigger bitch. got bleach hair ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42500</th>\n",
       "      <td>1</td>\n",
       "      <td>yea fuck you RT  IF YOURE A NIGGER FUCKING UNF...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>yea fuck you rt  if youre a nigger fucking unf...</td>\n",
       "      <td>yea fuck rt youre nigger fucking unfollow me, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42501</th>\n",
       "      <td>1</td>\n",
       "      <td>bro. U gotta chill RT  Dog FUCK KP that dumb n...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>bro. u gotta chill rt  dog fuck kp that dumb n...</td>\n",
       "      <td>bro. u gotta chill rt dog fuck kp dumb nigger ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42502 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                    comment_cleaned  \\\n",
       "0          0  wow it is totally unreasonable to assume that ...   \n",
       "1          0  a WHITE FUCKIN MALE is out to destroy  strong,...   \n",
       "2          0  he probably just didn't want to read them beca...   \n",
       "3          0  it's like he's saying we're entering a post ge...   \n",
       "4          0  but it was clearly only dismissed because of d...   \n",
       "...      ...                                                ...   \n",
       "42497      1  black ppl aren't expected to do anything, depe...   \n",
       "42498      1  turner did not withhold his disappointment. Tu...   \n",
       "42499      1  i swear to God. This dumb nigger bitch. I have...   \n",
       "42500      1  yea fuck you RT  IF YOURE A NIGGER FUCKING UNF...   \n",
       "42501      1  bro. U gotta chill RT  Dog FUCK KP that dumb n...   \n",
       "\n",
       "       Words Per Tweet                              comment_cleaned_lower  \\\n",
       "0                 25.0  wow it is totally unreasonable to assume that ...   \n",
       "1                 18.0  a white fuckin male is out to destroy  strong,...   \n",
       "2                 23.0  he probably just didn't want to read them beca...   \n",
       "3                 21.0  it's like he's saying we're entering a post ge...   \n",
       "4                 19.0  but it was clearly only dismissed because of d...   \n",
       "...                ...                                                ...   \n",
       "42497             42.0  black ppl aren't expected to do anything, depe...   \n",
       "42498             45.0  turner did not withhold his disappointment. tu...   \n",
       "42499             20.0  i swear to god. this dumb nigger bitch. i have...   \n",
       "42500             15.0  yea fuck you rt  if youre a nigger fucking unf...   \n",
       "42501             14.0  bro. u gotta chill rt  dog fuck kp that dumb n...   \n",
       "\n",
       "                                 text_without_stop_words  \n",
       "0      wow totally unreasonable assume agency covered...  \n",
       "1      white fuckin male destroy strong, independent ...  \n",
       "2      probably want read illegal read news media see...  \n",
       "3      like he's saying we're entering post gender so...  \n",
       "4      clearly dismissed death threats even though li...  \n",
       "...                                                  ...  \n",
       "42497  black ppl expected anything, depended anything...  \n",
       "42498  turner withhold disappointment. turner called ...  \n",
       "42499  swear god. dumb nigger bitch. got bleach hair ...  \n",
       "42500  yea fuck rt youre nigger fucking unfollow me, ...  \n",
       "42501  bro. u gotta chill rt dog fuck kp dumb nigger ...  \n",
       "\n",
       "[42502 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1eb45b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = merged_df['comment_cleaned_lower']\n",
    "y = merged_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c1a9843",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7ca30fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((29751,), (12751,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75e6f9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if i saw this type of person in school i would bully them too 1\n"
     ]
    }
   ],
   "source": [
    "print(X_test[34464], y_test[34464])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c62f00",
   "metadata": {},
   "source": [
    "Let's use this comment as a prediction example later on, as it is pretty clear that it is bullying."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fab0f2",
   "metadata": {},
   "source": [
    "## Defining our baseline accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51873644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    9599\n",
       "0    3152\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "922062b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy score: 0.1910\n"
     ]
    }
   ],
   "source": [
    "baseline_accuracy = (2435/(y_test.value_counts().sum()))\n",
    "print('Baseline accuracy score: {0:0.4f}'. format(baseline_accuracy))\n",
    "#our baseline accuracy is quite low because we took care of having balanced classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ee7706",
   "metadata": {},
   "source": [
    "## Training a Multinomial Naives Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28cebe6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize text reviews to numbers\n",
    "vec = CountVectorizer(stop_words='english')\n",
    "#vec = TfidfVectorizer(stop_words='english')\n",
    "X_train = vec.fit_transform(X_train).toarray()\n",
    "X_test = vec.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad659a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd6f0c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test[:300], y_test[:300])\n",
    "#interesting in this dataset, with TfidfVectorizer accuracy =0.81, with CountVectorizer accuracy=0.92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61563593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making a prediction on a sentence within the test set\n",
    "model.predict(vec.transform(['if i saw this type of person in school i would bully them too']))\n",
    "#correct predicted label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc77ac92",
   "metadata": {},
   "source": [
    "Correct predicted label (1 = bullying)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
